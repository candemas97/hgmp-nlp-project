{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IR - TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.feature_extraction.text\n",
    "import sklearn.metrics.pairwise\n",
    "import pandas\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import spacy\n",
    "import simplemma\n",
    "import random\n",
    "model_es = spacy.load(\"es_core_news_sm\")\n",
    "def reemplazar_tildes(texto: str) -> str:\n",
    "    reemplazos = {\"á\": \"a\", \"é\": \"e\", \"í\": \"i\", \"ó\": \"o\", \"ú\": \"u\"}\n",
    "    for original, reemplazo in reemplazos.items():\n",
    "        texto = texto.replace(original, reemplazo)\n",
    "    return texto\n",
    "def normalize_text(text: str) -> str:\n",
    "    doc = model_es(\" \".join(simplemma.text_lemmatizer(text, lang=\"es\")))\n",
    "    return \" \".join([reemplazar_tildes(str(token)) for token in doc if token.is_alpha and not token.is_stop])\n",
    "df_normalize = pandas.read_csv(\"./data_normalize.csv\")\n",
    "corpus = df_normalize[\"normalize\"].to_list()\n",
    "vectorizer = sklearn.feature_extraction.text.TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "def process_query(query: str) -> str:\n",
    "    return normalize_text(query)\n",
    "def get_query_vector(processed_query: str) -> np.ndarray:\n",
    "    query_vector = vectorizer.transform([processed_query]).toarray()\n",
    "    return query_vector\n",
    "def get_song_recommendations(query_vector: np.ndarray, top_n=5) -> pandas.DataFrame:\n",
    "    cosine_similarities = sklearn.metrics.pairwise.cosine_similarity(query_vector, X).flatten()\n",
    "    related_docs_indices = cosine_similarities.argsort()[: -top_n - 1 : -1]\n",
    "    return df_normalize.iloc[related_docs_indices]\n",
    "def search_and_recommend(query: str, top_n=5) -> pandas.DataFrame:\n",
    "    processed_query = process_query(query)\n",
    "    query_vector = get_query_vector(processed_query)\n",
    "    recommendations = get_song_recommendations(query_vector, top_n)\n",
    "    return recommendations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IR - WORD2VEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataleida\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# nltk.download(\"all\", quiet=True)\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "import scipy\n",
    "from scipy import spatial\n",
    "import pandas as pd\n",
    "wordvectors_file_vec = \"../../../../embeddings-l-model.vec\"\n",
    "# cantidad = 100000\n",
    "model = KeyedVectors.load_word2vec_format(wordvectors_file_vec)  # , limit=cantidad)\n",
    "ruta = \"../../../data/data.csv\"\n",
    "\n",
    "data = pd.read_csv(ruta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"unido_todo\"] = (\n",
    "    ((data[\"Artista\"] + \" \") * 5)\n",
    "    + ((data[\"Titulo\"] + \" \") * 5)\n",
    "    + data[\"Cancion\"]  # Se multiplica por 5 para darle un mayor peso a artista y titulo\n",
    ")\n",
    "stop_words = set(stopwords.words(\"spanish\"))\n",
    "spanishstemmer = SnowballStemmer(\"spanish\")\n",
    "def preprocesamiento_stemas(text: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Función encargada de prepocesar la data de las canciones\n",
    "    \"\"\"\n",
    "    text = str(text)\n",
    "    text = text.lower()\n",
    "    text = \"\".join([word for word in text if word not in string.punctuation])\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    stema = [spanishstemmer.stem(w) for w in tokens]  # devuelve palabras stemizadas\n",
    "    return \" \".join(stema)\n",
    "X = data[\"unido_todo\"].apply(preprocesamiento_stemas)\n",
    "X.head()\n",
    "def embeddings(word: str) -> np.array:\n",
    "    \"\"\"\n",
    "    Función encargada de realizar los embeddings de las palabras\n",
    "    \"\"\"\n",
    "    if word in model.key_to_index:\n",
    "        return model.get_vector(word)\n",
    "    else:\n",
    "        return np.zeros(300)\n",
    "diccionario = {}\n",
    "for idx, fila in enumerate(X):\n",
    "    average_vector = np.mean(\n",
    "        np.array([embeddings(palabra) for palabra in fila.split()]), axis=0\n",
    "    )\n",
    "    d1 = {idx: (average_vector)}\n",
    "    diccionario.update(d1)\n",
    "def similaridad(query_embedding: np.array, average_vec: np.array) -> float:\n",
    "    \"\"\"\n",
    "    Calcular la similitud del coseno\n",
    "    \"\"\"\n",
    "    sim = [(1 - scipy.spatial.distance.cosine(query_embedding, average_vec))]\n",
    "    return sim\n",
    "def seleccion_canciones_word2vec(query: str) -> list:\n",
    "    \"\"\"\n",
    "    Función que calcula distancias entre query y canciones.\n",
    "    \"\"\"\n",
    "    query_words = np.mean(\n",
    "        np.array(\n",
    "            [embeddings(palabra) for palabra in preprocesamiento_stemas(query).split()],\n",
    "            dtype=float,\n",
    "        ),\n",
    "        axis=0,\n",
    "    )\n",
    "    rank = []\n",
    "    for k, v in diccionario.items():\n",
    "        rank.append((k, similaridad(query_words, v)))  # data['Titulo'][k]\n",
    "    rank = sorted(rank, key=lambda t: t[1], reverse=True)\n",
    "    print(\"Canciones relacionadas: \")\n",
    "    return rank[:20]\n",
    "def main(texto: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Función principal para encontrar la canción solicitada\n",
    "    \"\"\"\n",
    "    canciones_respuesta = seleccion_canciones_word2vec(texto)\n",
    "    diccionario_resultado = {\"Titulo\": [], \"Artista\": [], \"Similaridad\": []}\n",
    "    for cancion in canciones_respuesta:\n",
    "        diccionario_resultado[\"Titulo\"].append(data[\"Titulo\"][cancion[0]])\n",
    "        diccionario_resultado[\"Artista\"].append(data[\"Artista\"][cancion[0]])\n",
    "        diccionario_resultado[\"Similaridad\"].append(np.round(cancion[1][0],4))\n",
    "    return pd.DataFrame(diccionario_resultado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simplemma import simple_tokenizer\n",
    "def get_tokens(text: str) -> str:\n",
    "    doc = model_es(\" \".join(simple_tokenizer(text)))\n",
    "    return [reemplazar_tildes(str(token)) for token in doc if token.is_alpha and not token.is_stop]\n",
    "\n",
    "def get_random_query(cancion,n_palabras_query=5):\n",
    "    tokens = get_tokens(cancion)\n",
    "    longitud_cancion = len(tokens)\n",
    "    try:\n",
    "        ultimo_token_query = max(longitud_cancion - n_palabras_query,1)\n",
    "        # print(ultimo_token_query)\n",
    "        pos_query = np.random.randint(0,ultimo_token_query)\n",
    "        # print(pos_query)\n",
    "        query = \" \".join(tokens[pos_query:min(pos_query+n_palabras_query,len(tokens))])\n",
    "        return query\n",
    "    except:\n",
    "        print('Exception')\n",
    "        return \"lasdlasd\"\n",
    "  \n",
    "def resultado_prediccion(row,top_n=5):\n",
    "    letra_cancion = row['Cancion']\n",
    "    target_idx = row.name\n",
    "    query = get_random_query(letra_cancion)\n",
    "    predicted_idxs = search_and_recommend(query,top_n=top_n).index.tolist()\n",
    "    return int(target_idx in predicted_idxs), target_idx, predicted_idxs, query\n",
    "\n",
    "def evaluar(df,tamaño_muestra=100):\n",
    "    sample_idxs = np.random.choice(df.index.tolist(),size=tamaño_muestra)\n",
    "    df_eval = df.loc[sample_idxs,:]\n",
    "    info = df_eval.apply(resultado_prediccion,top_n=5,axis=1)\n",
    "    res = np.array([x for x,y,z,a in info])\n",
    "    target_idx = [y for x,y,z,a in info]\n",
    "    predicted_idxs = [z for x,y,z,a in info]\n",
    "    query = [a for x,y,z,a in info]\n",
    "    return res.mean(), res, target_idx, predicted_idxs, query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1d-E2d-E3d-E4d-E5d-E6d-E7d-E8d-E9d-E10d-E11d-E12d-E13d-E14d-E15d-E16d-E17d-E18d-E19d-E20d-\n",
      "Accuracy Promedio = 0.6478\n"
     ]
    }
   ],
   "source": [
    "accs = []\n",
    "resultados = []\n",
    "ti = []\n",
    "pi = []\n",
    "q = []\n",
    "for i in range(20):\n",
    "    acc, res, target_idx, predicted_idxs, query = evaluar(df_normalize,tamaño_muestra=200)\n",
    "    accs.append(acc)\n",
    "    resultados.append(res)\n",
    "    ti.append(target_idx)\n",
    "    pi.append(predicted_idxs)\n",
    "    q.append(query)\n",
    "    \n",
    "    print(\"E\"+str(i+1)+\"d-\",end=\"\")\n",
    "print(\"\")\n",
    "acc_mean = np.array(accs).mean()\n",
    "print(\"Accuracy Promedio = \"+str(np.round(acc_mean,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322\n",
      "[2184, 634, 2265, 1139, 623]\n",
      "vida mundo acabara imposible existir\n"
     ]
    }
   ],
   "source": [
    "ej = 10\n",
    "print(ti[0][ej])\n",
    "print(pi[0][ej])\n",
    "print(q[0][ej])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canciones relacionadas: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titulo</th>\n",
       "      <th>Artista</th>\n",
       "      <th>Similaridad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hola Beba</td>\n",
       "      <td>Farruko</td>\n",
       "      <td>0.7222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Te Llama Te Busco</td>\n",
       "      <td>Kaleth Morales</td>\n",
       "      <td>0.7106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alguien Más (remix) (part. Carin Leon)</td>\n",
       "      <td>Andy Rivera</td>\n",
       "      <td>0.7051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alguien Más (remix) (part. Carin Leon)</td>\n",
       "      <td>Andy Rivera</td>\n",
       "      <td>0.7051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No Se Como Se Llama</td>\n",
       "      <td>Adriana Lucía</td>\n",
       "      <td>0.7014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Alguien Más</td>\n",
       "      <td>Andy Rivera</td>\n",
       "      <td>0.7012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Alguien Más</td>\n",
       "      <td>Andy Rivera</td>\n",
       "      <td>0.7012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Asia</td>\n",
       "      <td>Willie Colon</td>\n",
       "      <td>0.6966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ya Se Apagó La Llama (part. Ken-Y)</td>\n",
       "      <td>Chino &amp;amp; Nacho</td>\n",
       "      <td>0.6944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Llamada Perdida</td>\n",
       "      <td>Morat</td>\n",
       "      <td>0.6900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Melancólicos Anónimos</td>\n",
       "      <td>Sebastián Yatra</td>\n",
       "      <td>0.6890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hasta El Amanecer</td>\n",
       "      <td>Nicky Jam</td>\n",
       "      <td>0.6857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Las 12 (part. Mackie)</td>\n",
       "      <td>Kevin Roldán</td>\n",
       "      <td>0.6851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>confesión</td>\n",
       "      <td>Feid</td>\n",
       "      <td>0.6829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>EL CUARTO DE FERXXO</td>\n",
       "      <td>Feid</td>\n",
       "      <td>0.6813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Brindo Con El Alma</td>\n",
       "      <td>Diomedes Díaz</td>\n",
       "      <td>0.6811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Barrio Antioquia</td>\n",
       "      <td>Blessd</td>\n",
       "      <td>0.6810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ganas</td>\n",
       "      <td>Grupo Niche</td>\n",
       "      <td>0.6804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Bebiendo Sola (part. Myke Towers)</td>\n",
       "      <td>Camilo</td>\n",
       "      <td>0.6787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Dharma (part. Jorge Celedón y Rosario)</td>\n",
       "      <td>Sebastián Yatra</td>\n",
       "      <td>0.6778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Titulo            Artista  Similaridad\n",
       "0                                Hola Beba            Farruko       0.7222\n",
       "1                        Te Llama Te Busco     Kaleth Morales       0.7106\n",
       "2   Alguien Más (remix) (part. Carin Leon)        Andy Rivera       0.7051\n",
       "3   Alguien Más (remix) (part. Carin Leon)        Andy Rivera       0.7051\n",
       "4                      No Se Como Se Llama      Adriana Lucía       0.7014\n",
       "5                              Alguien Más        Andy Rivera       0.7012\n",
       "6                              Alguien Más        Andy Rivera       0.7012\n",
       "7                                     Asia       Willie Colon       0.6966\n",
       "8       Ya Se Apagó La Llama (part. Ken-Y)  Chino &amp; Nacho       0.6944\n",
       "9                          Llamada Perdida              Morat       0.6900\n",
       "10                   Melancólicos Anónimos    Sebastián Yatra       0.6890\n",
       "11                       Hasta El Amanecer          Nicky Jam       0.6857\n",
       "12                   Las 12 (part. Mackie)       Kevin Roldán       0.6851\n",
       "13                               confesión               Feid       0.6829\n",
       "14                     EL CUARTO DE FERXXO               Feid       0.6813\n",
       "15                      Brindo Con El Alma      Diomedes Díaz       0.6811\n",
       "16                        Barrio Antioquia             Blessd       0.6810\n",
       "17                                   Ganas        Grupo Niche       0.6804\n",
       "18       Bebiendo Sola (part. Myke Towers)             Camilo       0.6787\n",
       "19  Dharma (part. Jorge Celedón y Rosario)    Sebastián Yatra       0.6778"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main('Holi yo me llamo Pepito Perez')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
